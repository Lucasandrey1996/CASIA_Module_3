# Documentation du Processus de Chargement des DonnÃ©es

## Vue d'ensemble

Ce document dÃ©crit le processus complet de chargement des donnÃ©es dans l'architecture Medallion (Bronze, Silver, Gold) pour le projet Databricks. Le processus suit une approche ETL (Extract, Transform, Load) en plusieurs Ã©tapes, avec gestion de l'historisation des donnÃ©es via SCD2 (Slowly Changing Dimension Type 2).

---

## Architecture Medallion

L'architecture Medallion est organisÃ©e en trois couches :

- **Bronze** : DonnÃ©es brutes, copie exacte de la source
- **Silver** : DonnÃ©es nettoyÃ©es et enrichies avec historisation (SCD2)
- **Gold** : DonnÃ©es agrÃ©gÃ©es et structurÃ©es pour l'analyse (modÃ¨le en Ã©toile)

---

## Ã‰tape 1 : Initialisation (01_Init.py)

### Objectif
CrÃ©er l'infrastructure de base de donnÃ©es et dÃ©finir la structure des tables pour chaque couche de l'architecture Medallion.

### Actions rÃ©alisÃ©es

#### 1.1 Nettoyage initial
- Suppression des bases de donnÃ©es existantes (bronze, silver, gold) si elles existent
- Permet de repartir sur une base propre lors de l'initialisation

#### 1.2 CrÃ©ation de l'architecture Medallion
- CrÃ©ation du catalogue `lua_lakehouse`
- CrÃ©ation des trois bases de donnÃ©es :
  - `lua_lakehouse.bronze`
  - `lua_lakehouse.silver`
  - `lua_lakehouse.gold`

#### 1.3 CrÃ©ation des tables Silver
Les tables Silver sont crÃ©Ã©es avec :
- **ClÃ© primaire surrogÃ©e** : `_tf_id` (auto-incrÃ©mentÃ©e)
- **Colonnes mÃ©tier** : Colonnes issues de la source
- **Colonnes techniques pour SCD2** :
  - `_tf_valid_from` : Date de dÃ©but de validitÃ© de l'enregistrement
  - `_tf_valid_to` : Date de fin de validitÃ© (NULL = enregistrement actif)
  - `_tf_create_date` : Date de crÃ©ation
  - `_tf_update_date` : Date de derniÃ¨re mise Ã  jour

**Tables crÃ©Ã©es :**
- `silver.address`
- `silver.customer`
- `silver.customer_address`
- `silver.product`
- `silver.product_category`
- `silver.product_description`
- `silver.product_model`
- `silver.product_model_product_description`
- `silver.sales_order_header`
- `silver.sales_order_detail`

#### 1.4 CrÃ©ation des tables Gold

**Table de dimension : `dim_calendar`**
- Table de calendrier gÃ©nÃ©rÃ©e pour la pÃ©riode 2000-2030
- Contient des attributs temporels (annÃ©e, mois, jour, semaine, trimestre fiscal, etc.)
- ClÃ© primaire : `_tf_dim_calendar_id` (format : YYYYMMDD)

**Table de dimension : `dim_geography`**
- ClÃ© primaire surrogÃ©e : `_tf_dim_geography_id`
- Attributs gÃ©ographiques prÃ©fixÃ©s par `geo_`
- Enregistrement "N/A" initialisÃ© avec ID = -9

**Table de dimension : `dim_customer`**
- ClÃ© primaire surrogÃ©e : `_tf_dim_customer_id`
- Attributs clients prÃ©fixÃ©s par `cust_`
- Enregistrement "N/A" initialisÃ© avec ID = -9

**Table de faits : `fact_sales`**
- ClÃ© primaire surrogÃ©e : `_tf_fact_sales_id`
- ClÃ©s Ã©trangÃ¨res vers les dimensions :
  - `_tf_dim_calendar_id` â†’ `dim_calendar`
  - `_tf_dim_customer_id` â†’ `dim_customer`
  - `_tf_dim_geography_id` â†’ `dim_geography`
- Mesures : quantitÃ©s, prix unitaires, remises, totaux

---

## Ã‰tape 2 : Chargement Bronze (11_ETL_Bronze_SQL.sql)

### Objectif
IngÃ©rer les donnÃ©es brutes depuis la source (AdventureWorks) vers la couche Bronze sans transformation.

### Principe
Copie directe des donnÃ©es source vers Bronze. Aucune transformation n'est appliquÃ©e.

### Tables chargÃ©es

1. **SalesOrderDetail** : DÃ©tails des commandes
   - Source : `lua_adventureworks.saleslt.SalesOrderDetail`

2. **SalesOrderHeader** : En-tÃªtes des commandes
   - Source : `lua_adventureworks.saleslt.SalesOrderHeader`

3. **Product** : Produits
   - Source : `lua_adventureworks.saleslt.Product`

4. **ProductCategory** : CatÃ©gories de produits
   - Source : `lua_adventureworks.saleslt.ProductCategory`

5. **Address** : Adresses
   - Source : `lua_adventureworks.saleslt.Address`

6. **Customer** : Clients
   - Source : `lua_adventureworks.saleslt.Customer`

7. **CustomerAddress** : Association client â†” adresse
   - Source : `lua_adventureworks.saleslt.CustomerAddress`

8. **ProductDescription** : Descriptions de produits
   - Source : `lua_adventureworks.saleslt.ProductDescription`

9. **ProductModel** : ModÃ¨les de produits
   - Source : `lua_adventureworks.saleslt.ProductModel`

10. **ProductModelProductDescription** : Association modÃ¨le â†” description (culture)
   - Source : `lua_adventureworks.saleslt.ProductModelProductDescription`

### Exclusions (metadata)
Les tables de metadata ne sont **pas** chargÃ©es dans Bronze (ex. `dbo.ErrorLog`, `dbo.BuildVersion`) : on ingÃ¨re uniquement les tables du schÃ©ma `SalesLT`.

### MÃ©thode
Utilisation de `CREATE OR REPLACE TABLE ... AS SELECT *` pour une copie complÃ¨te Ã  chaque exÃ©cution.

---

## Ã‰tape 3 : Chargement Silver (21_ETL_Silver_SQL.sql)

### Objectif
Transformer et charger les donnÃ©es de Bronze vers Silver avec gestion de l'historisation (SCD2).

### Principe SCD2
Slowly Changing Dimension Type 2 : conservation de l'historique des changements en crÃ©ant de nouveaux enregistrements pour chaque modification.

### Processus de chargement incrÃ©mental

Pour chaque table, le processus utilise deux opÃ©rations `MERGE` successives :

#### Phase 1 : Fermeture des enregistrements modifiÃ©s/supprimÃ©s

1. **DÃ©tection des modifications** :
   - Comparaison des valeurs entre Bronze (source) et Silver (cible)
   - Si diffÃ©rence dÃ©tectÃ©e sur un enregistrement actif (`_tf_valid_to IS NULL`)

2. **Fermeture de l'ancien enregistrement** :
   - Mise Ã  jour de `_tf_valid_to` avec la date de chargement
   - Mise Ã  jour de `_tf_update_date`

3. **Gestion des suppressions** :
   - Si un enregistrement existe en Silver mais plus en Bronze (`WHEN NOT MATCHED BY SOURCE`)
   - Fermeture de l'enregistrement en dÃ©finissant `_tf_valid_to`

#### Phase 2 : Insertion des nouveaux enregistrements

1. **Insertion des nouveaux enregistrements** :
   - Nouveaux enregistrements de Bronze
   - Nouvelles versions d'enregistrements modifiÃ©s (aprÃ¨s fermeture de l'ancien)

2. **Initialisation des colonnes techniques** :
   - `_tf_valid_from` = date de chargement
   - `_tf_valid_to` = NULL (enregistrement actif)
   - `_tf_create_date` = date de chargement
   - `_tf_update_date` = date de chargement

### Tables traitÃ©es

#### 3.1 Table `address`
- Transformation des noms de colonnes (PascalCase â†’ snake_case)
- Suivi des modifications sur : address_line1, address_line2, city, state_province, country_region, postal_code, rowguid, modified_date

#### 3.2 Table `customer`
- Transformation des noms de colonnes
- Suivi des modifications sur tous les attributs clients (name_style, title, first_name, middle_name, last_name, suffix, company_name, sales_person, email_address, phone, password_hash, password_salt, rowguid, modified_date)

#### 3.3 Table `sales_order_detail`
- ClÃ© composite : `sales_order_id` + `sales_order_detail_id`
- Suivi des modifications sur : order_qty, product_id, unit_price, unit_price_discount, line_total, rowguid, modified_date

#### 3.4 Table `sales_order_header`
- ClÃ© : `sales_order_id`
- Suivi des modifications sur tous les attributs de commande (revision_number, order_date, due_date, ship_date, status, online_order_flag, sales_order_number, purchase_order_number, account_number, customer_id, ship_to_address_id, bill_to_address_id, ship_method, credit_card_approval_code, sub_total, tax_amt, freight, total_due, comment, rowguid, modified_date)

#### 3.5 Table `customer_address`
- ClÃ© composite : `customer_id` + `address_id`
- Suivi des modifications sur : address_type, rowguid, modified_date

#### 3.6 Table `product_category`
- ClÃ© : `product_category_id`
- Suivi des modifications sur : parent_product_category_id, name, rowguid, modified_date

#### 3.7 Table `product_description`
- ClÃ© : `product_description_id`
- Suivi des modifications sur : description, rowguid, modified_date

#### 3.8 Table `product_model`
- ClÃ© : `product_model_id`
- Suivi des modifications sur : name, catalog_description, rowguid, modified_date

#### 3.9 Table `product_model_product_description`
- ClÃ© composite : `product_model_id` + `product_description_id` + `culture`
- Suivi des modifications sur : rowguid, modified_date

#### 3.10 Table `product`
- ClÃ© : `product_id`
- Suivi des modifications sur : lâ€™ensemble des attributs produit (dont product_number, color, standard_cost, list_price, size, weight, product_category_id, product_model_id, sell_start_date, sell_end_date, discontinued_date, thumbnail_photo, thumbnail_photo_file_name, rowguid, modified_date)

### Note (scripts Bronze SQL vs PySpark)
Si vous utilisez `12_ETL_Bronze_PySpark.py` au lieu de `11_ETL_Bronze_SQL.sql`, vÃ©rifiez quâ€™il charge bien aussi les tables ajoutÃ©es (CustomerAddress, ProductDescription, ProductModel, ProductModelProductDescription), sinon lâ€™ETL Silver Ã©chouera sur des tables Bronze manquantes.

### Variable de chargement
- `load_date` : Timestamp unique pour chaque exÃ©cution, utilisÃ© pour `_tf_valid_from` et `_tf_valid_to`

---

## Ã‰tape 4 : Chargement Gold - Dimensions (31_ETL_Gold_Dim_SQL.sql)

### Objectif
Charger les tables de dimension dans la couche Gold Ã  partir des donnÃ©es Silver nettoyÃ©es.

### Principe
- Utilisation uniquement des enregistrements actifs de Silver (`WHERE _tf_valid_to IS NULL`)
- Gestion des valeurs NULL avec `COALESCE` et valeurs par dÃ©faut 'N/A'
- OpÃ©ration `MERGE` pour mise Ã  jour incrÃ©mentale

### Tables de dimension chargÃ©es

#### 4.1 `dim_geography`
- **Source** : `silver.address` (enregistrements actifs uniquement)
- **Transformation** :
  - Mapping des colonnes avec prÃ©fixe `geo_`
  - Gestion des NULL avec 'N/A'
  - ClÃ© de correspondance : `geo_address_id`
- **Logique MERGE** :
  - **WHEN MATCHED** : Mise Ã  jour si diffÃ©rence dÃ©tectÃ©e sur les attributs gÃ©ographiques
  - **WHEN NOT MATCHED** : Insertion des nouvelles adresses

#### 4.2 `dim_customer`
- **Source** : `silver.customer` (enregistrements actifs uniquement)
- **Transformation** :
  - Mapping des colonnes avec prÃ©fixe `cust_`
  - Exclusion des colonnes sensibles (password_hash, password_salt)
  - Gestion des NULL avec 'N/A'
  - ClÃ© de correspondance : `cust_customer_id`
- **Logique MERGE** :
  - **WHEN MATCHED** : Mise Ã  jour si diffÃ©rence dÃ©tectÃ©e sur les attributs clients
  - **WHEN NOT MATCHED** : Insertion des nouveaux clients

### Note importante
La table `dim_calendar` est crÃ©Ã©e lors de l'initialisation (01_Init.py) et ne nÃ©cessite pas de chargement incrÃ©mental car elle est gÃ©nÃ©rÃ©e statiquement.

---

## Ã‰tape 5 : Chargement Gold - Faits (32_ETL_Gold_Fact_SQL.sql)

### Objectif
Charger la table de faits `fact_sales` dans la couche Gold en joignant les donnÃ©es Silver et les dimensions Gold.

### Processus

#### 5.1 CrÃ©ation d'une vue temporaire `_tmp_fact_sales`
La vue assemble les donnÃ©es nÃ©cessaires :

**Sources :**
- `silver.sales_order_detail` (table principale)
- `silver.sales_order_header` (JOIN sur sales_order_id)
- `silver.customer` (JOIN via sales_order_header)
- `silver.address` (JOIN via bill_to_address_id)
- `gold.dim_customer` (JOIN pour obtenir la clÃ© surrogÃ©e)
- `gold.dim_geography` (JOIN pour obtenir la clÃ© surrogÃ©e)

**Transformations :**
- **ClÃ© calendrier** : Calcul de `_tf_dim_calendar_id` Ã  partir de `order_date` (format YYYYMMDD)
- **ClÃ© client** : RÃ©cupÃ©ration de `_tf_dim_customer_id` depuis `dim_customer`
- **ClÃ© gÃ©ographie** : RÃ©cupÃ©ration de `_tf_dim_geography_id` depuis `dim_geography`
- **Gestion des valeurs manquantes** :
  - ClÃ©s Ã©trangÃ¨res : Utilisation de -9 (enregistrement "N/A") si non trouvÃ©
  - Mesures : Utilisation de 0 si NULL
- **Filtrage** : Uniquement les enregistrements actifs (`_tf_valid_to IS NULL`)

**Colonnes gÃ©nÃ©rÃ©es :**
- `sales_order_id`, `sales_order_detail_id`
- `_tf_dim_calendar_id`, `_tf_dim_customer_id`, `_tf_dim_geography_id`
- `sales_order_qty`, `sales_unit_price`, `sales_unit_price_discount`, `sales_line_total`

#### 5.2 Chargement dans `fact_sales`
- **ClÃ© composite** : `sales_order_id` + `sales_order_detail_id`
- **Logique MERGE** :
  - **WHEN MATCHED** : Mise Ã  jour si diffÃ©rence dÃ©tectÃ©e sur les clÃ©s Ã©trangÃ¨res ou les mesures
  - **WHEN NOT MATCHED** : Insertion des nouvelles lignes de commande

### Relations dimensionnelles
La table de faits est liÃ©e aux dimensions via :
- `_tf_dim_calendar_id` â†’ `dim_calendar(_tf_dim_calendar_id)`
- `_tf_dim_customer_id` â†’ `dim_customer(_tf_dim_customer_id)`
- `_tf_dim_geography_id` â†’ `dim_geography(_tf_dim_geography_id)`

---

## Ã‰tape 6 : Tests SCD2 (99_testing_SCD2.sql)

### Objectif
Valider le bon fonctionnement de l'historisation SCD2 dans la couche Silver.

### ScÃ©narios de test

#### 6.1 Test de mise Ã  jour (UPDATE)
1. **SÃ©lection initiale** : Consultation des adresses de la ville "Bothell" en Bronze
2. **Modification** : Mise Ã  jour du code postal et de la date de modification
   ```sql
   UPDATE address SET PostalCode = '12345', ModifiedDate = current_timestamp() 
   WHERE City = 'Bothell';
   ```
3. **VÃ©rification** : AprÃ¨s exÃ©cution de l'ETL Silver, vÃ©rifier que :
   - L'ancien enregistrement a `_tf_valid_to` dÃ©fini
   - Un nouvel enregistrement existe avec `_tf_valid_to IS NULL`
   - Les deux enregistrements ont le mÃªme `address_id`

#### 6.2 Test de suppression (DELETE)
1. **SÃ©lection initiale** : Consultation des adresses de la ville "Surrey"
2. **Suppression** : Suppression des enregistrements
   ```sql
   DELETE FROM address WHERE City = 'Surrey';
   ```
3. **VÃ©rification** : AprÃ¨s exÃ©cution de l'ETL Silver, vÃ©rifier que :
   - Les enregistrements ont `_tf_valid_to` dÃ©fini (fermeture)

#### 6.3 Test d'insertion (INSERT)
1. **SÃ©lection** : Consultation des derniÃ¨res adresses
2. **Simulation d'insertion** : Modification d'un ID existant (simulation)
   ```sql
   UPDATE bronze.Address SET AddressID = 11383 WHERE AddressID = 1105;
   ```
3. **VÃ©rification** : AprÃ¨s exÃ©cution de l'ETL Silver, vÃ©rifier que :
   - L'ancien ID (1105) est fermÃ©
   - Le nouvel ID (11383) est prÃ©sent

### RequÃªtes de validation
```sql
-- VÃ©rification des mises Ã  jour (plusieurs versions pour un mÃªme ID)
SELECT * FROM address 
WHERE city = 'Bothell' 
ORDER BY address_id, _tf_valid_from;

-- VÃ©rification des suppressions (enregistrements fermÃ©s)
SELECT * FROM address 
WHERE city = 'Surrey' 
ORDER BY address_id, _tf_valid_from;

-- VÃ©rification des insertions
SELECT * FROM address 
WHERE address_id IN (11383, 1105);
```

---

## Flux de donnÃ©es complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Source System   â”‚
â”‚ AdventureWorks  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Extraction
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   BRONZE Layer  â”‚  â† 11_ETL_Bronze_SQL.sql
â”‚  (DonnÃ©es brutes)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ Transformation + Historisation (SCD2)
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SILVER Layer   â”‚  â† 21_ETL_Silver_SQL.sql
â”‚ (DonnÃ©es nettoyÃ©esâ”‚
â”‚  + Historique)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚ AgrÃ©gation + ModÃ¨le en Ã©toile
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   GOLD Layer    â”‚
â”‚  (Analytics)    â”‚
â”‚                 â”‚
â”‚  Dimensions:    â”‚  â† 31_ETL_Gold_Dim_SQL.sql
â”‚  - dim_calendar â”‚
â”‚  - dim_geographyâ”‚
â”‚  - dim_customer â”‚
â”‚                 â”‚
â”‚  Facts:         â”‚  â† 32_ETL_Gold_Fact_SQL.sql
â”‚  - fact_sales   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Ordre d'exÃ©cution recommandÃ©

1. **01_Init.py** : Initialisation de l'infrastructure (une seule fois)
2. **11_ETL_Bronze_SQL.sql** : Chargement des donnÃ©es brutes
3. **21_ETL_Silver_SQL.sql** : Transformation et historisation
4. **31_ETL_Gold_Dim_SQL.sql** : Chargement des dimensions
5. **32_ETL_Gold_Fact_SQL.sql** : Chargement des faits
6. **99_testing_SCD2.sql** : Tests de validation (optionnel)

---

## Colonnes techniques standardisÃ©es

Toutes les tables utilisent un prÃ©fixe `_tf_` (technical fields) pour les colonnes techniques :

- `_tf_id` : ClÃ© primaire surrogÃ©e (Silver)
- `_tf_dim_*_id` : ClÃ©s primaires des dimensions (Gold)
- `_tf_fact_*_id` : ClÃ©s primaires des faits (Gold)
- `_tf_valid_from` : Date de dÃ©but de validitÃ© (SCD2)
- `_tf_valid_to` : Date de fin de validitÃ© (SCD2, NULL = actif)
- `_tf_create_date` : Date de crÃ©ation de l'enregistrement
- `_tf_update_date` : Date de derniÃ¨re mise Ã  jour

---

## Bonnes pratiques observÃ©es

1. **Gestion des valeurs NULL** : Utilisation de `COALESCE` avec valeurs par dÃ©faut ('N/A' pour les dimensions, 0 pour les mesures)
2. **ClÃ©s surrogÃ©es** : Utilisation systÃ©matique de clÃ©s auto-incrÃ©mentÃ©es pour l'indÃ©pendance vis-Ã -vis de la source
3. **Historisation** : ImplÃ©mentation SCD2 pour traÃ§abilitÃ© complÃ¨te des changements
4. **Chargement incrÃ©mental** : Utilisation de `MERGE` pour Ã©viter les doublons et optimiser les performances
5. **SÃ©paration des prÃ©occupations** : Chaque couche a un rÃ´le bien dÃ©fini (raw, cleaned, aggregated)
6. **Tests** : Scripts de validation pour garantir la qualitÃ© des donnÃ©es

---

## Notes importantes

- âš ï¸ **Attention** : Le script `01_Init.py` supprime toutes les donnÃ©es existantes. Ã€ utiliser uniquement lors de l'initialisation.
- ğŸ”„ **Chargement incrÃ©mental** : Les scripts Silver et Gold utilisent `MERGE` pour un chargement incrÃ©mental efficace.
- ğŸ“Š **ModÃ¨le en Ã©toile** : La couche Gold suit un modÃ¨le en Ã©toile classique (dimensions + faits) optimisÃ© pour l'analyse.
- ğŸ” **TraÃ§abilitÃ©** : L'historisation SCD2 permet de reconstituer l'Ã©tat des donnÃ©es Ã  n'importe quel moment dans le temps.
